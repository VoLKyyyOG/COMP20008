{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elements Of Data Processing (2021S1) - Week 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Folding\n",
    "- Case folding removes all case distinctions present in a string (i.e lower and upper cases are matched regardless). \n",
    "- It is used for caseless matching when it the text input isn't always guaranteed to have the correct grammar. \n",
    "- Essentially, casefolding is a more aggressive version of the `str.lower()` method that is designed to take into account *much more* unique Unicode characters and make them more comparable.\n",
    "- You can use `str.lower()` when your text field is purely ASCII Text, but you should use `str.casefold()` when working with Unicode text or user input.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\"> Exercise 1 </span>\n",
    "\n",
    "Use appropriate functions to covert `\"Whereof one cannot speak, thereof one must be silent.\"` into:\n",
    "- Lower case.\n",
    "- Upper case.\n",
    "- Casefold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"Whereof one cannot speak, thereof one must be silent.\"\n",
    "\n",
    "print(s.lower())\n",
    "print(s.upper())\n",
    "print(s.casefold())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Language Processing (NLP)\n",
    "- Preprocessing steps for NLP can be done using the `nltk` library.\n",
    "- Provides useful functions for tokenizing, stemming, lemmatizing, and vectorizing text fields.\n",
    "- We don't always need to remove punctuation - sometimes you want to keep the natural language features to help split apart [contractions](https://www.thoughtco.com/contractions-commonly-used-informal-english-1692651).\n",
    "\n",
    "The example below parses the `speech` string and outputs a frequency dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech = \"\"\"Four score and seven years ago our fathers brought forth on this continent, \n",
    "a new nation, conceived in Liberty, and dedicated to the proposition that all men are created equal. \n",
    "Now we are engaged in a great civil war, testing whether that nation, or any nation so conceived and so dedicated, \n",
    "can long endure. We are met on a great battle-field of that war. \n",
    "We have come to dedicate a portion of that field, as a final resting place for those who here \n",
    "gave their lives that that nation might live. It is altogether fitting and proper that we should do this. \n",
    "But, in a larger sense, we can not dedicate -- we can not consecrate -- we can not hallow -- this ground. \n",
    "The brave men, living and dead, who struggled here, have consecrated it, far above our poor power to add or detract. \n",
    "The world will little note, nor long remember what we say here, but it can never forget what they did here.\n",
    "It is for us the living, rather, to be dedicated here to the unfinished work which they who \n",
    "fought here have thus far so nobly advanced. It is rather for us to be here dedicated to the \n",
    "great task remaining before us -- that from these honored dead we take increased devotion to \n",
    "that cause for which they gave the last full measure of devotion -- that we here highly resolve \n",
    "that these dead shall not have died in vain -- that this nation, under God, shall have a new birth \n",
    "of freedom -- and that government of the people, by the people, for the people, shall not perish from the earth.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize words - similar to str.split()\n",
    "words = nltk.word_tokenize(speech)\n",
    "\n",
    "# create a set of stopwords (i.e and, or, is, it, etc)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# initialise the porter stemmer function\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['four', 'score', 'seven', 'year', 'ago', 'father', 'brought', 'forth', 'contin', ',', 'new', 'nation', ',', 'conceiv', 'liberti', ',', 'dedic', 'proposit', 'men', 'creat', 'equal', '.', 'now', 'engag', 'great', 'civil', 'war', ',', 'test', 'whether', 'nation', ',', 'nation', 'conceiv', 'dedic', ',', 'long', 'endur', '.', 'We', 'met', 'great', 'battle-field', 'war', '.', 'We', 'come', 'dedic', 'portion', 'field', ',', 'final', 'rest', 'place', 'gave', 'live', 'nation', 'might', 'live', '.', 'It', 'altogeth', 'fit', 'proper', '.', 'but', ',', 'larger', 'sens', ',', 'dedic', '--', 'consecr', '--', 'hallow', '--', 'ground', '.', 'the', 'brave', 'men', ',', 'live', 'dead', ',', 'struggl', ',', 'consecr', ',', 'far', 'poor', 'power', 'add', 'detract', '.', 'the', 'world', 'littl', 'note', ',', 'long', 'rememb', 'say', ',', 'never', 'forget', '.', 'It', 'us', 'live', ',', 'rather', ',', 'dedic', 'unfinish', 'work', 'fought', 'thu', 'far', 'nobli', 'advanc', '.', 'It', 'rather', 'us', 'dedic', 'great', 'task', 'remain', 'us', '--', 'honor', 'dead', 'take', 'increas', 'devot', 'caus', 'gave', 'last', 'full', 'measur', 'devot', '--', 'highli', 'resolv', 'dead', 'shall', 'die', 'vain', '--', 'nation', ',', 'god', ',', 'shall', 'new', 'birth', 'freedom', '--', 'govern', 'peopl', ',', 'peopl', ',', 'peopl', ',', 'shall', 'perish', 'earth', '.']\n"
     ]
    }
   ],
   "source": [
    "stemmed_words = [ps.stem(word) for word in words if word not in stop_words]\n",
    "print(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", 22\n",
      ". 10\n",
      "-- 7\n",
      "dedic 6\n",
      "nation 5\n",
      "live 4\n",
      "great 3\n",
      "It 3\n",
      "dead 3\n",
      "us 3\n",
      "shall 3\n",
      "peopl 3\n",
      "new 2\n",
      "conceiv 2\n",
      "men 2\n",
      "war 2\n",
      "long 2\n",
      "We 2\n",
      "gave 2\n",
      "consecr 2\n",
      "the 2\n",
      "far 2\n",
      "rather 2\n",
      "devot 2\n",
      "four 1\n",
      "score 1\n",
      "seven 1\n",
      "year 1\n",
      "ago 1\n",
      "father 1\n",
      "brought 1\n",
      "forth 1\n",
      "contin 1\n",
      "liberti 1\n",
      "proposit 1\n",
      "creat 1\n",
      "equal 1\n",
      "now 1\n",
      "engag 1\n",
      "civil 1\n",
      "test 1\n",
      "whether 1\n",
      "endur 1\n",
      "met 1\n",
      "battle-field 1\n",
      "come 1\n",
      "portion 1\n",
      "field 1\n",
      "final 1\n",
      "rest 1\n",
      "place 1\n",
      "might 1\n",
      "altogeth 1\n",
      "fit 1\n",
      "proper 1\n",
      "but 1\n",
      "larger 1\n",
      "sens 1\n",
      "hallow 1\n",
      "ground 1\n",
      "brave 1\n",
      "struggl 1\n",
      "poor 1\n",
      "power 1\n",
      "add 1\n",
      "detract 1\n",
      "world 1\n",
      "littl 1\n",
      "note 1\n",
      "rememb 1\n",
      "say 1\n",
      "never 1\n",
      "forget 1\n",
      "unfinish 1\n",
      "work 1\n",
      "fought 1\n",
      "thu 1\n",
      "nobli 1\n",
      "advanc 1\n",
      "task 1\n",
      "remain 1\n",
      "honor 1\n",
      "take 1\n",
      "increas 1\n",
      "caus 1\n",
      "last 1\n",
      "full 1\n",
      "measur 1\n",
      "highli 1\n",
      "resolv 1\n",
      "die 1\n",
      "vain 1\n",
      "god 1\n",
      "birth 1\n",
      "freedom 1\n",
      "govern 1\n",
      "perish 1\n",
      "earth 1\n"
     ]
    }
   ],
   "source": [
    "freq_stem = Counter(stemmed_words)\n",
    "for word, freq in sorted(freq_stem.items(), key=lambda x: -x[1]):\n",
    "    print(word, freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\"> Exercise 2 </span>\n",
    "\n",
    "- Modify the example above to use a `WordNet` Lemmatizer instead of a Porter Stemmer.\n",
    "- What are the differences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", 22\n",
      ". 10\n",
      "-- 7\n",
      "nation 5\n",
      "dedicated 4\n",
      "great 3\n",
      "It 3\n",
      "dead 3\n",
      "u 3\n",
      "shall 3\n",
      "people 3\n",
      "new 2\n",
      "conceived 2\n",
      "men 2\n",
      "war 2\n",
      "long 2\n",
      "We 2\n",
      "dedicate 2\n",
      "gave 2\n",
      "The 2\n",
      "living 2\n",
      "far 2\n",
      "rather 2\n",
      "devotion 2\n",
      "Four 1\n",
      "score 1\n",
      "seven 1\n",
      "year 1\n",
      "ago 1\n",
      "father 1\n",
      "brought 1\n",
      "forth 1\n",
      "continent 1\n",
      "Liberty 1\n",
      "proposition 1\n",
      "created 1\n",
      "equal 1\n",
      "Now 1\n",
      "engaged 1\n",
      "civil 1\n",
      "testing 1\n",
      "whether 1\n",
      "endure 1\n",
      "met 1\n",
      "battle-field 1\n",
      "come 1\n",
      "portion 1\n",
      "field 1\n",
      "final 1\n",
      "resting 1\n",
      "place 1\n",
      "life 1\n",
      "might 1\n",
      "live 1\n",
      "altogether 1\n",
      "fitting 1\n",
      "proper 1\n",
      "But 1\n",
      "larger 1\n",
      "sense 1\n",
      "consecrate 1\n",
      "hallow 1\n",
      "ground 1\n",
      "brave 1\n",
      "struggled 1\n",
      "consecrated 1\n",
      "poor 1\n",
      "power 1\n",
      "add 1\n",
      "detract 1\n",
      "world 1\n",
      "little 1\n",
      "note 1\n",
      "remember 1\n",
      "say 1\n",
      "never 1\n",
      "forget 1\n",
      "unfinished 1\n",
      "work 1\n",
      "fought 1\n",
      "thus 1\n",
      "nobly 1\n",
      "advanced 1\n",
      "task 1\n",
      "remaining 1\n",
      "honored 1\n",
      "take 1\n",
      "increased 1\n",
      "cause 1\n",
      "last 1\n",
      "full 1\n",
      "measure 1\n",
      "highly 1\n",
      "resolve 1\n",
      "died 1\n",
      "vain 1\n",
      "God 1\n",
      "birth 1\n",
      "freedom 1\n",
      "government 1\n",
      "perish 1\n",
      "earth 1\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "lemmatized_words = [lem.lemmatize(word) for word in words if word not in stop_words]\n",
    "\n",
    "freq_lemma = Counter(lemmatized_words)\n",
    "for word, freq in sorted(freq_lemma.items(), key=lambda x: -x[1]):\n",
    "    print(word, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('But', 1),\n",
       " ('Four', 1),\n",
       " ('God', 1),\n",
       " ('Liberty', 1),\n",
       " ('Now', 1),\n",
       " ('The', 2),\n",
       " ('advanced', 1),\n",
       " ('altogether', 1),\n",
       " ('cause', 1),\n",
       " ('conceived', 2),\n",
       " ('consecrate', 1),\n",
       " ('consecrated', 1),\n",
       " ('continent', 1),\n",
       " ('created', 1),\n",
       " ('dedicate', 2),\n",
       " ('dedicated', 4),\n",
       " ('devotion', 2),\n",
       " ('died', 1),\n",
       " ('endure', 1),\n",
       " ('engaged', 1),\n",
       " ('fitting', 1),\n",
       " ('government', 1),\n",
       " ('highly', 1),\n",
       " ('honored', 1),\n",
       " ('increased', 1),\n",
       " ('life', 1),\n",
       " ('little', 1),\n",
       " ('live', 1),\n",
       " ('living', 2),\n",
       " ('measure', 1),\n",
       " ('nobly', 1),\n",
       " ('people', 3),\n",
       " ('proposition', 1),\n",
       " ('remaining', 1),\n",
       " ('remember', 1),\n",
       " ('resolve', 1),\n",
       " ('resting', 1),\n",
       " ('sense', 1),\n",
       " ('struggled', 1),\n",
       " ('testing', 1),\n",
       " ('thus', 1),\n",
       " ('u', 3),\n",
       " ('unfinished', 1)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# differences between the two sets\n",
    "set(freq_lemma.items()).difference(set(freq_stem.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset: Smokers\n",
    "In the first twenty rows, there are seven errors that all fall into one of the following categories:\n",
    "- Semantic Errors\n",
    "- Range Errors\n",
    "- Format Errors\n",
    "\n",
    "Identify the errors and what category they fall into. \n",
    "- Where possible, fix the errors manually and save the new spreadsheet as `smoking-info-corrected.csv`\n",
    "- Suggest how you would write a program to detect them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>State</th>\n",
       "      <th>Smoke everyday</th>\n",
       "      <th>Smoke some days</th>\n",
       "      <th>Former smoker</th>\n",
       "      <th>Never smoked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>1995</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>18.70%</td>\n",
       "      <td>2.70%</td>\n",
       "      <td>25.20%</td>\n",
       "      <td>53.50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>1995</td>\n",
       "      <td>Washington</td>\n",
       "      <td>17.50%</td>\n",
       "      <td>2.40%</td>\n",
       "      <td>29.90%</td>\n",
       "      <td>50.20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>1995</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>23.70%</td>\n",
       "      <td>1.90%</td>\n",
       "      <td>23.30%</td>\n",
       "      <td>51.10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>1995</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>18.20%</td>\n",
       "      <td>3.50%</td>\n",
       "      <td>27.60%</td>\n",
       "      <td>50.70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>1995</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>19.10%</td>\n",
       "      <td>2.90%</td>\n",
       "      <td>26.80%</td>\n",
       "      <td>51.20%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year          State Smoke everyday Smoke some days Former smoker  \\\n",
       "871  1995       Virginia         18.70%           2.70%        25.20%   \n",
       "872  1995     Washington         17.50%           2.40%        29.90%   \n",
       "873  1995  West Virginia         23.70%           1.90%        23.30%   \n",
       "874  1995      Wisconsin         18.20%           3.50%        27.60%   \n",
       "875  1995        Wyoming         19.10%           2.90%        26.80%   \n",
       "\n",
       "    Never smoked  \n",
       "871       53.50%  \n",
       "872       50.20%  \n",
       "873       51.10%  \n",
       "874       50.70%  \n",
       "875       51.20%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Year                int64\n",
       "State              object\n",
       "Smoke everyday     object\n",
       "Smoke some days    object\n",
       "Former smoker      object\n",
       "Never smoked       object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "df = pd.read_csv('smoking_data_us_1995_2010.csv')\n",
    "display(df.tail())\n",
    "display(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.1\n",
      "8.5\n",
      "105.00%\n",
      "twenty-three point 6 percent\n",
      "33.4\n",
      "83.7\n"
     ]
    }
   ],
   "source": [
    "# length of a percentages are at most 7 characters (XXX.XX%)\n",
    "DECIMAL_LENGTH = 6\n",
    "\n",
    "for col in df.columns[2:]:\n",
    "    print(df[col].apply(lambda x: float(x.rstrip('%')) if len(x) <= DECIMAL_LENGTH else print(x)).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     876.000000\n",
       "mean     2002.683790\n",
       "std         5.640406\n",
       "min      1995.000000\n",
       "25%      1999.000000\n",
       "50%      2003.000000\n",
       "75%      2007.000000\n",
       "max      2100.000000\n",
       "Name: Year, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Year'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twenty-three point 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from word2number import w2n\n",
    "import re\n",
    "\n",
    "word_num = 'twenty-three point 6 percent'\n",
    "\n",
    "# strip percent\n",
    "word_num = re.sub(r'(\\spercent)?', r'', word_num)\n",
    "print(word_num)\n",
    "\n",
    "w2n.word_to_num(word_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As you can see, although libraries can help, they aren't always perfect.\n",
    "- Part of your work may be to discuss with the client and Business Analysts on fixing these issues manually..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\"> Exercise 3 </span>\n",
    "\n",
    "Write python code for the following tasks:\n",
    "- Import your file `smoking_data_us_1995_2010_corrected.csv` into a pandas data frame\n",
    "- Remove the percentage symbols from the data. \n",
    "- For removing/replacing characters see [here](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.replace.html)\n",
    "- After the removals, convert all the strings to numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>State</th>\n",
       "      <th>Smoke everyday</th>\n",
       "      <th>Smoke some days</th>\n",
       "      <th>Former smoker</th>\n",
       "      <th>Never smoked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>1995</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>18.70%</td>\n",
       "      <td>2.70%</td>\n",
       "      <td>25.20%</td>\n",
       "      <td>53.50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>1995</td>\n",
       "      <td>Washington</td>\n",
       "      <td>17.50%</td>\n",
       "      <td>2.40%</td>\n",
       "      <td>29.90%</td>\n",
       "      <td>50.20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>1995</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>23.70%</td>\n",
       "      <td>1.90%</td>\n",
       "      <td>23.30%</td>\n",
       "      <td>51.10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>1995</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>18.20%</td>\n",
       "      <td>3.50%</td>\n",
       "      <td>27.60%</td>\n",
       "      <td>50.70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>1995</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>19.10%</td>\n",
       "      <td>2.90%</td>\n",
       "      <td>26.80%</td>\n",
       "      <td>51.20%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year          State Smoke everyday Smoke some days Former smoker  \\\n",
       "871  1995       Virginia         18.70%           2.70%        25.20%   \n",
       "872  1995     Washington         17.50%           2.40%        29.90%   \n",
       "873  1995  West Virginia         23.70%           1.90%        23.30%   \n",
       "874  1995      Wisconsin         18.20%           3.50%        27.60%   \n",
       "875  1995        Wyoming         19.10%           2.90%        26.80%   \n",
       "\n",
       "    Never smoked  \n",
       "871       53.50%  \n",
       "872       50.20%  \n",
       "873       51.10%  \n",
       "874       50.70%  \n",
       "875       51.20%  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('smoking_data_us_1995_2010_corrected.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                int64\n",
       "State              object\n",
       "Smoke everyday     object\n",
       "Smoke some days    object\n",
       "Former smoker      object\n",
       "Never smoked       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>State</th>\n",
       "      <th>Smoke everyday</th>\n",
       "      <th>Smoke some days</th>\n",
       "      <th>Former smoker</th>\n",
       "      <th>Never smoked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>1995</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>18.7</td>\n",
       "      <td>2.7</td>\n",
       "      <td>25.2</td>\n",
       "      <td>53.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>1995</td>\n",
       "      <td>Washington</td>\n",
       "      <td>17.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>29.9</td>\n",
       "      <td>50.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>1995</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>23.7</td>\n",
       "      <td>1.9</td>\n",
       "      <td>23.3</td>\n",
       "      <td>51.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>1995</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>18.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>27.6</td>\n",
       "      <td>50.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>1995</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>19.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>26.8</td>\n",
       "      <td>51.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year          State  Smoke everyday  Smoke some days  Former smoker  \\\n",
       "871  1995       Virginia            18.7              2.7           25.2   \n",
       "872  1995     Washington            17.5              2.4           29.9   \n",
       "873  1995  West Virginia            23.7              1.9           23.3   \n",
       "874  1995      Wisconsin            18.2              3.5           27.6   \n",
       "875  1995        Wyoming            19.1              2.9           26.8   \n",
       "\n",
       "     Never smoked  \n",
       "871          53.5  \n",
       "872          50.2  \n",
       "873          51.1  \n",
       "874          50.7  \n",
       "875          51.2  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in df.columns[2:]:\n",
    "    df[col] = df[col].str.rstrip('%').astype(float)\n",
    "    # df[col] = df[col].apply(lambda x: float(x.strip('%')))\n",
    "    \n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                 int64\n",
       "State               object\n",
       "Smoke everyday     float64\n",
       "Smoke some days    float64\n",
       "Former smoker      float64\n",
       "Never smoked       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
