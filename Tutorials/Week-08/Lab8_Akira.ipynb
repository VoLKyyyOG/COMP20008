{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elements Of Data Processing (2021S1) - Week 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a way of ignoring errors\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "Consider the 1-dimensional data set with 10 data points {1,2,3,...10}. Show the iterations of the k-means algorithm using Euclidean distance when $k = 2$, and the random seeds are initialized to {1, 2}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# usually we don't specify the random points as sklearn has a built-in method of setting fixed random states\n",
    "initial_clusters = np.array([[1], [2]])\n",
    "data_points = np.array([[i] for i in range(1, 11)])\n",
    "\n",
    "kmean = KMeans(n_clusters=2, init=initial_clusters)\n",
    "kmean.fit(data_points)\n",
    "\n",
    "kmean.cluster_centers_, kmean.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Centroids at 2.5, 7.5\n",
    "- All data points below 4 belong to 2.5, all data points above 5 belong to 7.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "Repeat Exercise 1 using agglomerative hierarchical clustering and Euclidean distance with single linkage (min) criterion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `pdist` computes Pairwise Distance given some metric (i.e Euclidean)\n",
    "- `squareform` displays the results as a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points = np.array([[i] for i in range(1, 11)])\n",
    "\n",
    "distance = pdist(data_points, 'euclidean')\n",
    "\n",
    "print(sns.heatmap(squareform(distance)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `linkage` performs the  hierarchical/agglomerative clustering.\n",
    "- `method='single'` denotes our method - i.e choose the closest (min) point.\n",
    "    - Other ones include `average` (UPGMA algorithm);\n",
    "    - and `complete` (clusters are singletone, which are then sequentially combined into larger clusters until all elements end up being in the same cluster).\n",
    "- `dendrogram` plots the clusters\n",
    "\n",
    "Read More: https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc = linkage(distance, method='single')\n",
    "dendrogram(hc, labels=data_points)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As you can see, each point will only correspond to its neighbouring points (min distance away)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc2 = linkage(distance, method='complete')\n",
    "dendrogram(hc2, labels=data_points)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "- The bread and butter of most predictive models in industry.\n",
    "- Learn more in Linear Statistical Models (MAST30025). We only very very briefly cover it in EoDP!\n",
    "- The dataset is Boston house prices that comes with `sklearn`. Please see the description below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets \n",
    "import pandas as pd\n",
    "\n",
    "data = datasets.load_boston()\n",
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Linear Regression:\n",
    "- You need an `X` matrix (aka Design Matrix) which are the values you use to *predict*.\n",
    "- You also need a `y` matrix (aka Predictions) which are the values you want to *predict*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design Matrix\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction (MEDV)\n",
    "y = pd.DataFrame(data.target, columns=[\"MEDV\"])\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Linear Model\n",
    "- Let's fit a regression model using two variables `RM` (average number of rooms per dwelling) and `LSTAT` (% of lower status in the population) to predict `MEDV` (Median value of owner-occupied homes in \\$1000's)\n",
    "- `train_test_split` used to split our data into training and testing. We do this as we need to *evaluate* our model on data it **has not seen before**.\n",
    "- `mean_squared_error` (MSE) is a very common metric for evaluating our models' performance. It calculates the average error$^2$ and is used to compare two different models (useless on its own).\n",
    "- `r2_score` (R$^2$) is another metric for evaluating the models performance (though it's actually not that good, adjusted R$^2$ is better).\n",
    "\n",
    "#### Evaulation Metrics\n",
    "- MSE: The lower the better\n",
    "- R2: Between 0 and 1, where a high R2 indicates a better fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the design matrix using the two variables\n",
    "X = df[['RM', 'LSTAT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split it so that we have 80% data for training (finding the coefficients of our model)\n",
    "# and 20% for evaluating the model using MSE\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "lm = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict values of y given our hidden test set\n",
    "y_pred = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the first few results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:5], y_pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, our model seems to be roughly predicting within a reasonable amount away from the true expected predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "R2 = lm.score(X_test, y_test)\n",
    "MSE, R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- At the moment, MSE doesn't mean much as we don't have a model to compare it to;\n",
    "- but the R$^2$ suggests our model isn't doing quite well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4  \n",
    "Write out the fitted linear model in Example 1:\n",
    "- `alpha` is the intercept parameter.\n",
    "- `beta` is the array of coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = lm.intercept_\n",
    "beta = lm.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RM = X['RM'].values\n",
    "LSTAT = X['LSTAT'].values\n",
    "\n",
    "# add code below\n",
    "MEDV = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What do the coefficients indicate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "Residuals:\n",
    "- A residual is defined to be the difference between the observed value (true value) and the estimated value (our prediction).\n",
    "- If our estimates are good, then the residuals should be very close to the true errors.\n",
    "- For example, a model with perfect fit that can predict with 100% accuracy should have 0 residuals.\n",
    "\n",
    "Interpret the residuals for the test and training data of the model in Example 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_pred_test = lm.predict(X_test)\n",
    "y_pred_train = lm.predict(X_train)\n",
    "\n",
    "# calculate residuals\n",
    "residual_test = [true_val - estimated_val for true_val, estimated_val in zip(y_test, y_pred_test)]\n",
    "residual_train = [true_val - estimated_val for true_val, estimated_val in zip(y_train, y_pred_train)]\n",
    "\n",
    "# plot residuals\n",
    "plt.scatter(y_pred_test, residual_test, label='R^2 test', color='red')\n",
    "plt.scatter(y_pred_train, residual_train, label='R^2 train', alpha=0.15)\n",
    "\n",
    "# plot the 0 line (we want our residuals close to 0)\n",
    "plt.plot([min(y_pred_train), max(y_pred_train)], [0,0], color='green')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.title(\"Residual plot for LM\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Do the points have large residuals (differences between true and estimated)?\n",
    "    - We want small residuals that are close to 0.\n",
    "1. Is there a trend or bias in the residuals (i.e does the residuals look evenly spread and flat)?\n",
    "    - We don't want any bias or trend.\n",
    "1. Is there a pattern or correlation in the residuals (i.e is there some kind of relationship in the residuals)?\n",
    "    - We don't want any correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "Fit another linear model using all 13 variables to predict **MEDV**.\n",
    "- Compare the results with those of the model in Question 1 (looking at MSE and residual plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.values, y.values, test_size=0.2, random_state=42)\n",
    "\n",
    "lm_full = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "y_pred = lm_full.predict(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "R2 = lm_full.score(X_test, y_test)\n",
    "MSE, R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our MSE metric is much more useful.\n",
    "- What's the difference?\n",
    "- What does it imply?\n",
    "\n",
    "Likewise with R$^2$. Is our model better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_pred_test = lm_full.predict(X_test)\n",
    "y_pred_train = lm_full.predict(X_train)\n",
    "\n",
    "# calculate residuals\n",
    "residual_test = [true_val - estimated_val for true_val, estimated_val in zip(y_test, y_pred_test)]\n",
    "residual_train = [true_val - estimated_val for true_val, estimated_val in zip(y_train, y_pred_train)]\n",
    "\n",
    "# plot residuals\n",
    "plt.scatter(y_pred_test, residual_test, label='R^2 test', color='red')\n",
    "plt.scatter(y_pred_train, residual_train, label='R^2 train', alpha=0.15)\n",
    "\n",
    "# plot the 0 line (we want our residuals close to 0)\n",
    "plt.plot([min(y_pred_test), max(y_pred_test)], [0,0], color='green')\n",
    "\n",
    "plt.yticks(range(-20, 31, 10))\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.title(\"Residual plot for LM Full\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"res.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do the plots look similar or a bit more different?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
